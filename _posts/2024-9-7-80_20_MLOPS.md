---
layout: post
title: 80/20 MLOps
date: 2024-12-02 13:11:00
description: A Basic MLOps Setup With Kubeflow
tags: mlops, kubeflow, terraform
categories: mlops
featured: true
---

## 80/20 MLOps

You need to spin up an MLOps solution for a new team. Without deepy knowing the problem area, their budget or the software development cycle of this team, what solution could one recommend to have any team up and going quickly without spending needlessly and while maintaining evolveability of the platform down the line? 

In this post, we'll learn why a Kubeflow solution is right for 80% of ML platform use cases, why it saves on cost and how it allows teams to evolve their platform with their individual needs. Finally, we'll setup a multi-user science experimentation and productionization platform in 20 minutes on both AWS and Google Cloud. 

### Requirement 1: Iteration

This graphic of the CRISP cycle has been around since before the invention of the transformer, but the core rules still apply. Whether you're training a robot, ML is about experimentation, learning from the results, and iterating again as quickly and cheaply as possible. 

{% include figure.liquid loading="eager" path="assets/img/crisp_cycle.png" class="img-fluid rounded z-depth-1" zoomable=true %}

But when machine learning teams scale, the quickness of iteration is stimied by reacting to the needs of individual models and problem areas. Some models require distributed GPU clusters, others can be experimented on single CPU. Some have hard-to-configure dependency environments which must be shared seamlessly between scientists. Model serving creates another large layer of complexity, with batch vs online serving, event-driven vs response-based, and CICD requirements. 

### Requirement 2: Unified Development

An ideal MLOps solution will allow teams to manage the varying components of the machine learning cycle without jumping between different interfaces and solutions. A balkanized MLOps solution suffers from disparate code repos within a project, out of sync CICD and deployment processes, and untestable (and often unsecure) handoffs across architectures. 

The ideal solution unifies as much of the model development cycle as possible, including ETL, experimentation, model deployment, and monitoring. This fact has been recognized by industry leaders, as shown by the [Sagemaker Unified Studio announcement](https://aws.amazon.com/blogs/aws/introducing-the-next-generation-of-amazon-sagemaker-the-center-for-all-your-data-analytics-and-ai/) in Dec 2024.

### Requirement 3: Flexible Integration and Experimentation
ML use cases are as diverse as the different business cases and software environments they apply to. The standard terr

For these reasons, Kubernetes[3] stands out as a solution and is widely used across top tier tech companies and AI labs. Just prior to releasing ChatGPT, OpenAI described [scaling a Kubernetes cluster to 75000 nodes](https://openai.com/index/scaling-kubernetes-to-7500-nodes/).

### Non-Functional Requirements: Cost, Complexity, and Convenience

### Why A Kubernetes-based Solution
Why not a full-service ML platform like [Domino Data Labs](https://domino.ai/), H2O.ai, or even [Sagemaker Studio](https://aws.amazon.com/sagemaker/studio/)? Kubernetes lets ML Engineering teams scale on their own terms and best tailor their solutions to their own needs. Conversely, ML platforms lock users into their format and then annual subscription fees. At its a best, an internally-built containerized solution can be designed to be multi-cloud and avoid vendor lock-in. Finally, the advent of generative AI means organizations are experimenting with workflows which may have needs beyond what traditional ML platforms support. In order to fully empower AI teams to innovate, teams can give their engineers access to theoretically limitless compute and high flexibility. 

### Cloud Infra
Terraform is the most popular and versatile Infrastructure as Code (IaC) language. Importantly, its format can be used across cloud vendors. A basic Google Cloud 'Google Kubernetes Engine' (GKE) Kubeflow implementation is shown below. 

### Picking An ML Kubernetes Framework
Kubeflow, Metaflow, and Bodywork are potential ML Frameworks which run on Kubernetes. Kubeflow has multiple advantages. First, it is well-supported as it initially was developed Google and is now maintained by the Cloud Native Computing Foundation. Another strength is its thoroughness and customization. Kubeflow offers specialized Kubernetes operators [4] for Notebooks, Workflows and Schedules, Training, Model Tuning, Serving, Model registry and a central monitoring dashboard. These custom operators also provide a customization in that they allow users to device which components are necessary at a given time. This makes Kubeflow adjustable to small projects or enterprise scale, as opposed to say Metaflow which is more of an all-in-one solution meant for a large scale project. 

#### 1. Network & Subnets
Kubeflow components consist of pods (jobs, notebooks, pipeline steps) and services (microservices, load balancers) which need their own network and IP addresses. In the following terraform code, we create a network and a private subnet, with ip ranges split between pods and services. The subnet is private by default. In reality, we'll want to add a NAT gateway to at least allow outgoing internet traffic to retreive models from Huggingface or get data. If serving a public-facing model, we'd likely want a seperate public subnet fas well. 

```tf
# Network for Kubeflow
resource "google_compute_network" "kubeflow_network" {
    name = "${local.cluster_name}-network"
    auto_create_subnetworks = false
}

# Subnet for Kubeflow
resource "google_compute_subnetwork" "kubeflow_subnet" {
    name = "${local.cluster_name}-subnet"
    ip_cidr_range = "10.0.0.0/16"
    region = local.config.gcp_region
    network = google_compute_network.kubeflow_network.self_link

    secondary_ip_range {
        range_name = "pods"
        ip_cidr_range = "10.1.0.0/16"
    }

    secondary_ip_range {
        range_name = "services"
        ip_cidr_range = "10.2.0.0/16"
    }
}

```

#### 2. Kubernetes Cluster
We define our Kubernetes cluster in Google Kubernetes Engine (GKE). We remove the default node pool so that our node pool can be customized per workload. 

```tf
# GKE Cluster 

resource "google_container_cluster" "primary" {
    name = local.cluster_name
    location = local.gcp_region

    remove_default_node_pool = true
    initial_node_count = 1 

    # GKE Version
    min_master_version = local.config.gke_version

    # Workload Identity
    workload_identity_config {
       workload_pool = "${local.config.roject_id}.svc.id.goog"
    }

    # Network configuration for Kubeflow
    network = google_compute_network.kubeflow_network.self_link
    subnetwork = google_compute_subnetwork.kubeflow_subnet.self_link

    # IP allocation for pods and services
    ip_allocation_policy {
        cluster_secondary_range_name = "pods"
        services_secondary_range_name = "services"
    }

    # Enable network policy
    network_policy {
        enabled = true
    }

    # Addons
    addons_config {
        network_policy_config {
            disabled = false
        }
    }
}

```

#### 3. Service Accounts / Roles
Kubeflow nodes will need roles with permissions to execute in GCP cloud.
```tf
# Service Account for Kubeflow nodes
resource "google_service_account" "kubeflow_node_sa" {
    account_id = "${local.config.cluster_name}-node-sa"
    display_name = "Kubeflow Node Service Account"
}

resource "google_project_iam_member" "kubeflow_node_sa_roles" {
    for_each = toset([
        "roles/logging.logWriter",
        "roles/monitoring.metricWriter",
        "roles/monitoring.viewer",
        "roles/storage.objectViewer"
    ])
    
    project = local.config.project_id
    role = each.value
    member = "serviceAccount:${google_service_account.kubeflow_node_sa.email}"
}
```

#### 4. Node Pools

We'll include a node pool for gpu instances with 3 gpu nodes for our initial training run.

```tf
resource "google_container_node_pool" "kubeflow_gpu_pool" {
    name = "${local.config.cluster_name}-gpu-pool"
    location = local.config.gcp_region
    cluster = google_container_cluster.primary.name
    
    initial_node_count = 0
    
    autoscaling {
        min_node_count = 0
        max_node_count = 3
    }
    
    node_config {
        preemptible = true
        machine_type = "n1-standard-4"
        disk_size_gb = 100
        disk_type = "pd-standard"
        
        service_account = google_service_account.kubeflow_node_sa.email
        
        oauth_scopes = [
            "https://www.googleapis.com/auth/cloud-platform"
        ]
        
        labels = {
            purpose = "kubeflow-gpu"
        }
        
        metadata = {
            disable-legacy-endpoints = "true"
        }
        
        # GPU configuration
        guest_accelerator {
            type = "nvidia-tesla-t4"
            count = 3
        }
    }
    
    management {
        auto_repair = true
        auto_upgrade = true
    }
}
```

[See full file here](https://github.com/jamesdvance/MLOPtionS/blob/main/kubeflow_w_mlflow_gke/main.tf)

Running `terraform plan` will demonstrate the attributes of this stack. It should describe a simple cluster. Next, to deploy this cluster to our GCP project, we can run `terraform apply`. If this is a new project, we'll need to enable the GKE API for the project and also link the project to a billing account. 


### Installing Kubeflow
Kubernetes Deployments require Objects [10] which include a *spec* which describe the desired state of your application. Kubernetes works to ensure your application matches the spec,and uses the *status* to describe how the application is actually running. That spec is defined via a config file (usually YAML) called a *manifest*. Kubernetes offers a myriad of ways to install packages. Individual Kubeflow components can be installed via the [Kubeflow manifests repository](https://github.com/kubeflow/manifests). Kubeflow allows you to install the entire platform or individual components as needed. For sake of example, we'll install the training component. At time of writing I can install the stable release of the training componenent with the kubectl cli:
1. Authenticate our cluster with glcoud cli
```bash
gcloud container clusters get-credentials kubeflow-mlops     --region=us-central1 
```
2. Apply kubeflow training-operator manifest to our cluster
```bash 
kubectl apply -k "github.com/kubeflow/training-operator.git/manifests/overlays/standalone?ref=v1.7.0"
```
The output should look something like this 
```
namespace/kubeflow created
customresourcedefinition.apiextensions.k8s.io/mpijobs.kubeflow.org created
customresourcedefinition.apiextensions.k8s.io/mxjobs.kubeflow.org created
customresourcedefinition.apiextensions.k8s.io/paddlejobs.kubeflow.org created
customresourcedefinition.apiextensions.k8s.io/pytorchjobs.kubeflow.org created
customresourcedefinition.apiextensions.k8s.io/tfjobs.kubeflow.org created
customresourcedefinition.apiextensions.k8s.io/xgboostjobs.kubeflow.org created
serviceaccount/training-operator created
clusterrole.rbac.authorization.k8s.io/training-operator created
clusterrolebinding.rbac.authorization.k8s.io/training-operator created
service/training-operator created
deployment.apps/training-operator created
```

### Defining A Training Job
Thanks to our Kubeconfig file (created when we authenticated above) we can define a Python training job locally and run it on our distributed Kubernetes cluster. 

### Creating A Workflow
A Deployment

### Creating Seperate Node Pools

### Wrapping Up
Starting with Kubeflow is a good way to start understanding your team's needs and 

### Resources

[1][Spotify's cluster](https://github.com/spotify/terraform-gke-kubeflow-cluster)
[2] [Combinator.ml](https://combinator.ml/)
[3] [Kubernetes](https://kubernetes.io/docs/concepts/overview/)
[4] [Kubeflow Componenets](https://www.kubeflow.org/docs/components/)
[5] [Metaflow](https://metaflow.org/)
[6] [Bodywork](https://github.com/bodywork-ml/bodywork-core)
[7] [Kubernetes Manifest](https://kubernetes.io/docs/concepts/workloads/management/)
[8] [OpenAI Scaling Kubernetes](https://openai.com/index/scaling-kubernetes-to-7500-nodes/)
[9] [OpenAI Case Study Kubernetes](https://kubernetes.io/case-studies/openai/)
[10] [Kubernetes Objects](https://kubernetes.io/docs/concepts/overview/working-with-objects/#kubernetes-objects)
[11] [Swiss Army Cube](https://github.com/provectus/sak-kubeflow)
[12] [Kubeflow on EKS](https://registry.terraform.io/modules/young-ook/eks/aws/1.7.6/examples/kubeflow)